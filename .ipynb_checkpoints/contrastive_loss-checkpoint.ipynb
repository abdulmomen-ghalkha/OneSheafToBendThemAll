{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee1b9380-dd5f-4e8f-a7d7-e7db7c3b9bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset and graph setup complete.\n",
      "Graph: {0: [1, 2], 1: [0, 2], 2: [0, 1]}\n",
      "DataLoaders: 3 nodes ready.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import functional as TF\n",
    "from PIL import ImageFilter\n",
    "import random\n",
    "\n",
    "# ==== 1. Multi-modal MNIST Dataset ====\n",
    "class MultiModalMNIST(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        self.dataset = datasets.MNIST(root=\"./data\", train=train, download=True)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        \n",
    "        # Modality 1: original\n",
    "        m1 = TF.to_tensor(img)\n",
    "        # Modality 2: edge-detected\n",
    "        m2 = TF.to_tensor(img.filter(ImageFilter.FIND_EDGES))\n",
    "        # Modality 3: inverted\n",
    "        m3 = TF.to_tensor(TF.invert(img))\n",
    "        \n",
    "        return (m1.view(-1), m2.view(-1), m3.view(-1)), label  # flatten each modality\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "# --- Build training and testing sets ---\n",
    "train_dataset = MultiModalMNIST(train=True)\n",
    "test_dataset = MultiModalMNIST(train=False)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ==== 2. Graph Setup ====\n",
    "# We have 3 nodes (modality-specific learners)\n",
    "num_nodes = 3\n",
    "graph = {\n",
    "    0: [1, 2],\n",
    "    1: [0, 2],\n",
    "    2: [0, 1]\n",
    "}\n",
    "\n",
    "# Node-specific DataLoaders (extracting single modality)\n",
    "def modality_dataloader(dataset, modality_idx):\n",
    "    class SingleModality(Dataset):\n",
    "        def __init__(self, base_dataset, idx):\n",
    "            self.base = base_dataset\n",
    "            self.idx = idx\n",
    "        def __len__(self):\n",
    "            return len(self.base)\n",
    "        def __getitem__(self, i):\n",
    "            Xs, y = self.base[i]\n",
    "            return Xs[self.idx], y\n",
    "    return DataLoader(SingleModality(dataset, modality_idx), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "data_loaders = {i: modality_dataloader(train_dataset, i) for i in range(num_nodes)}\n",
    "\n",
    "# ==== 3. Node Encoders and Maps ====\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Node Encoder ---\n",
    "class NodeEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "# --- Maps ---\n",
    "class RestrictionMap(nn.Module):  # Node -> Edge\n",
    "    def __init__(self, node_dim, edge_dim):\n",
    "        super().__init__()\n",
    "        self.map = nn.Linear(node_dim, edge_dim, bias=False)\n",
    "    def forward(self, h):\n",
    "        return self.map(h)\n",
    "\n",
    "class TransportMap(nn.Module):  # Edge -> Node\n",
    "    def __init__(self, edge_dim, node_dim):\n",
    "        super().__init__()\n",
    "        self.map = nn.Linear(edge_dim, node_dim, bias=False)\n",
    "    def forward(self, z):\n",
    "        return self.map(z)\n",
    "\n",
    "# --- Initialize models ---\n",
    "input_dim = 28*28      # flattened MNIST\n",
    "embedding_dim = 64\n",
    "edge_dim = 32\n",
    "\n",
    "encoders = {i: NodeEncoder(input_dim, embedding_dim) for i in range(num_nodes)}\n",
    "\n",
    "# Initialize P and Q maps\n",
    "P_maps = {i: {} for i in range(num_nodes)}\n",
    "Q_maps = {i: {} for i in range(num_nodes)}\n",
    "for i in range(num_nodes):\n",
    "    for j in graph[i]:\n",
    "        P_maps[i][j] = RestrictionMap(embedding_dim, edge_dim)\n",
    "        Q_maps[i][j] = TransportMap(edge_dim, embedding_dim)\n",
    "\n",
    "# ==== 4. Optimizers ====\n",
    "optimizer_dict = {\n",
    "    i: torch.optim.Adam(list(encoders[i].parameters()) +\n",
    "                        [p for P in P_maps[i].values() for p in P.parameters()] +\n",
    "                        [p for Q in Q_maps[i].values() for p in Q.parameters()],\n",
    "                        lr=1e-3)\n",
    "    for i in range(num_nodes)\n",
    "}\n",
    "\n",
    "print(\"Dataset and graph setup complete.\")\n",
    "print(f\"Graph: {graph}\")\n",
    "print(f\"DataLoaders: {len(data_loaders)} nodes ready.\")\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c334b-6c76-4154-9344-5bdb2eee8586",
   "metadata": {},
   "source": [
    "# implementation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926e6e44-2e63-4574-8a9f-644fb634e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Loss Functions ---\n",
    "def contrastive_loss(local_emb, transported_emb, temperature=0.1):\n",
    "    local_norm = F.normalize(local_emb, dim=-1)\n",
    "    transported_norm = F.normalize(transported_emb, dim=-1)\n",
    "    \n",
    "    logits = torch.matmul(local_norm, transported_norm.T) / temperature\n",
    "    labels = torch.arange(local_emb.size(0), device=local_emb.device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "def sheaf_laplacian_loss(h_i, h_j, P_ij, P_ji):\n",
    "    \"\"\"\n",
    "    ||P_ij h_i - P_ji h_j||^2\n",
    "    \"\"\"\n",
    "    z_i = P_ij(h_i)\n",
    "    z_j = P_ji(h_j)\n",
    "    return F.mse_loss(z_i, z_j)\n",
    "\n",
    "\n",
    "# --- One Training Step ---\n",
    "def decentralized_training_step(node_id, batch_x, \n",
    "                                neighbors_data, \n",
    "                                encoder, P_maps, Q_maps, \n",
    "                                lambda_lap=1.0, beta_contrast=1.0):\n",
    "    \"\"\"\n",
    "    One node-centric sheaf training step\n",
    "    \"\"\"\n",
    "    # --- Local embedding ---\n",
    "    h_i = encoder(batch_x)  # [B, d_node]\n",
    "\n",
    "    lap_loss, contrast_loss = 0.0, 0.0\n",
    "    for j, (x_j, enc_j) in neighbors_data.items():\n",
    "        h_j = enc_j(x_j)\n",
    "\n",
    "        # Laplacian term\n",
    "        lap_loss += sheaf_laplacian_loss(\n",
    "            h_i, h_j, P_maps[node_id][j], P_maps[j][node_id]\n",
    "        )\n",
    "\n",
    "        # Transport embedding from j->i\n",
    "        transported = Q_maps[node_id][j](\n",
    "            P_maps[j][node_id](h_j)\n",
    "        )\n",
    "        \n",
    "        # Contrastive term\n",
    "        contrast_loss += contrastive_loss(h_i, transported)\n",
    "    \n",
    "    return lambda_lap * lap_loss + beta_contrast * contrast_loss\n",
    "\n",
    "\n",
    "# --- Main Training Loop ---\n",
    "def train_sheaf_decentralized(graph, data_loaders, encoders, P_maps, Q_maps,\n",
    "                              optimizer_dict, epochs=10, device=device):\n",
    "    \"\"\"\n",
    "    graph: adjacency dict {i: [j1, j2, ...]}\n",
    "    data_loaders: dict {i: DataLoader}\n",
    "    encoders: dict {i: NodeEncoder}\n",
    "    P_maps, Q_maps: dict {i: {j: map}}\n",
    "    optimizer_dict: dict {i: torch.optim.Optimizer}\n",
    "    \"\"\"\n",
    "    for i in encoders:\n",
    "        encoders[i].to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_losses = defaultdict(float)\n",
    "\n",
    "        # zip(*...) aligns batches across all nodes\n",
    "        for batch_nodes in zip(*data_loaders.values()):\n",
    "            # Compute local losses for each node\n",
    "            for i, batch in enumerate(batch_nodes):\n",
    "                x_i = batch[0].to(device)  # Assume (data, label)\n",
    "\n",
    "                # Collect neighbors\n",
    "                neighbors_data = {}\n",
    "                for j in graph[i]:\n",
    "                    x_j = batch_nodes[j][0].to(device)\n",
    "                    neighbors_data[j] = (x_j, encoders[j])\n",
    "\n",
    "                # Compute loss\n",
    "                loss = decentralized_training_step(\n",
    "                    i, x_i, neighbors_data, \n",
    "                    encoders[i], P_maps, Q_maps\n",
    "                )\n",
    "\n",
    "                optimizer_dict[i].zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer_dict[i].step()\n",
    "                \n",
    "                total_losses[i] += loss.item()\n",
    "\n",
    "        avg_loss = sum(total_losses.values()) / len(total_losses)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: avg loss {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffddd166-c07f-4231-9424-40bcd491f3b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_sheaf_decentralized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_maps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ_maps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m sheaf_node_eval(\n\u001b[0;32m      7\u001b[0m     graph, data_loaders, encoders, P_maps, Q_maps, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n",
      "Cell \u001b[1;32mIn[6], line 66\u001b[0m, in \u001b[0;36mtrain_sheaf_decentralized\u001b[1;34m(graph, data_loaders, encoders, P_maps, Q_maps, optimizer_dict, epochs, device)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03mgraph: adjacency dict {i: [j1, j2, ...]}\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mdata_loaders: dict {i: DataLoader}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;124;03moptimizer_dict: dict {i: torch.optim.Optimizer}\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m encoders:\n\u001b[1;32m---> 66\u001b[0m     \u001b[43mencoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     69\u001b[0m     total_losses \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\fmtl_sheaves\\lib\\site-packages\\torch\\nn\\modules\\module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\fmtl_sheaves\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\fmtl_sheaves\\lib\\site-packages\\torch\\nn\\modules\\module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\fmtl_sheaves\\lib\\site-packages\\torch\\nn\\modules\\module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\fmtl_sheaves\\lib\\site-packages\\torch\\nn\\modules\\module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\fmtl_sheaves\\lib\\site-packages\\torch\\cuda\\__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m     )\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    297\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "train_sheaf_decentralized(\n",
    "    graph, data_loaders, encoders, P_maps, Q_maps,\n",
    "    optimizer_dict, epochs=20, device=device\n",
    ")\n",
    "\n",
    "sheaf_node_eval(\n",
    "    graph, data_loaders, encoders, P_maps, Q_maps, device=device\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6db621-6b5e-404b-b9aa-60488ac6907b",
   "metadata": {},
   "source": [
    "# Implementation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e60b6d7-6a5f-4d55-8778-3ca20a73f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def decentralized_training_step(node_id, batch_x, \n",
    "                                neighbors_data, \n",
    "                                encoder, P_maps, Q_maps, \n",
    "                                lambda_lap=1.0, beta_contrast=1.0):\n",
    "    \"\"\"\n",
    "    node_id: int\n",
    "    batch_x: [B, input_dim] for local node\n",
    "    neighbors_data: dict {j: (batch_x_j, encoder_j)}\n",
    "    P_maps, Q_maps: dict {(i,j): RestrictionMap or TransportMap}\n",
    "    \"\"\"\n",
    "    B = batch_x.size(0)\n",
    "    \n",
    "    # --- Local embedding ---\n",
    "    h_i = encoder(batch_x)  # [B, d_node]\n",
    "    \n",
    "    # --- Compute outgoing messages ---\n",
    "    z_outgoing = {}\n",
    "    for j, P_ij in P_maps[node_id].items():\n",
    "        z_outgoing[j] = P_ij(h_i)  # [B, d_edge]\n",
    "\n",
    "    # --- Receive neighbor messages and compute losses ---\n",
    "    lap_loss, contrast_loss = 0.0, 0.0\n",
    "    for j, (x_j, enc_j) in neighbors_data.items():\n",
    "        h_j = enc_j(x_j)\n",
    "\n",
    "        # Laplacian term\n",
    "        z_i_to_j = P_maps[node_id][j](h_i)\n",
    "        z_j_to_i = P_maps[j][node_id](h_j)\n",
    "        lap_loss += F.mse_loss(z_i_to_j, z_j_to_i)\n",
    "\n",
    "        # Transported embedding: Q_ij(P_ji(h_j))\n",
    "        transported = Q_maps[node_id][j](z_j_to_i)\n",
    "        contrast_loss += contrastive_loss(h_i, transported)\n",
    "\n",
    "    total_loss = lambda_lap * lap_loss + beta_contrast * contrast_loss\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "def contrastive_loss(local_emb, transported_emb, temperature=0.1):\n",
    "    local_norm = F.normalize(local_emb, dim=-1)\n",
    "    transported_norm = F.normalize(transported_emb, dim=-1)\n",
    "    \n",
    "    logits = torch.matmul(local_norm, transported_norm.T) / temperature\n",
    "    labels = torch.arange(local_emb.size(0), device=local_emb.device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "\n",
    "def train_sheaf_decentralized(graph, data_loaders, encoders, P_maps, Q_maps,\n",
    "                              optimizer_dict, epochs=10, \n",
    "                              lambda_lap=1.0, beta_contrast=1.0,\n",
    "                              device=device):\n",
    "    \"\"\"\n",
    "    graph: adjacency dict {i: [j1, j2, ...]}\n",
    "    data_loaders: dict {i: DataLoader}\n",
    "    encoders: dict {i: NodeEncoder}\n",
    "    P_maps, Q_maps: dict {i: {j: map}}\n",
    "    optimizer_dict: dict {i: torch.optim.Optimizer}\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        total_losses = defaultdict(float)\n",
    "        batch_count = 0\n",
    "\n",
    "        for batch_nodes in zip(*data_loaders.values()):\n",
    "            # Each batch_nodes is a tuple: (x_i, y_i), ..., one per node\n",
    "            batch_count += 1\n",
    "\n",
    "            for i, batch in enumerate(batch_nodes):\n",
    "                batch_x = batch[0].to(device)  # assuming (x, y)\n",
    "\n",
    "                # Get neighbor batches\n",
    "                neighbors_data = {}\n",
    "                for j in graph[i]:\n",
    "                    x_j = batch_nodes[j][0].to(device)\n",
    "                    neighbors_data[j] = (x_j, encoders[j].to(device))\n",
    "\n",
    "                enc_i = encoders[i].to(device)\n",
    "                enc_i.train()\n",
    "\n",
    "                # Compute loss\n",
    "                loss = decentralized_training_step(\n",
    "                    i, batch_x, neighbors_data, enc_i, \n",
    "                    P_maps, Q_maps, \n",
    "                    lambda_lap, beta_contrast\n",
    "                )\n",
    "\n",
    "                optimizer_dict[i].zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer_dict[i].step()\n",
    "\n",
    "                total_losses[i] += loss.item()\n",
    "\n",
    "        avg_epoch_loss = sum(total_losses.values()) / len(total_losses)\n",
    "        print(f\"[Epoch {epoch+1}] Avg loss: {avg_epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d95340-2891-4b48-9f69-bba7b853e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sheaf_decentralized(\n",
    "    graph=your_graph_dict,\n",
    "    data_loaders=your_dataloaders,\n",
    "    encoders=your_node_encoders,\n",
    "    P_maps=your_restriction_maps,\n",
    "    Q_maps=your_transport_maps,\n",
    "    optimizer_dict=your_optimizer_dict,\n",
    "    epochs=20,\n",
    "    lambda_lap=1.0,\n",
    "    beta_contrast=1.0,\n",
    "    device=device\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
